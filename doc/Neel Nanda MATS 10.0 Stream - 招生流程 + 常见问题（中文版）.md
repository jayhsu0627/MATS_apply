# 关键信息

# Neel Nanda MATS 10.0 (2026年夏季)

## 招生流程 + 常见问题

## [**在此申请**](https://forms.matsprogram.org/neel10)

**截止日期：12月23日星期二 太平洋时间晚上11:59**  
([申请延期](https://forms.gle/VxUvBTcRAnnvc1YU7))

## 快速概览

* 花费 **约16小时（最多20小时）** 研究一个**你选择的机制可解释性研究问题**，并向我提交一份**研究报告 + 执行摘要**，说明你学到了什么（额外+2小时）。  
  * 请参阅其他标签页中的[**建议**](#how-to-produce-a-good-application-in-20-hours)、[**详细信息**]()和[**过往示例**]()。特别注意[**常见错误**列表](#common-mistakes)和[如何选择**我感兴趣的问题**]()！  
    * 特别说明：我通常对grokking、玩具模型或（大多数）SAE工作不感兴趣  
  * 关于如何开始研究任务、如何一般性地进行研究、如何确定项目范围等的建议，请查看我关于**如何成为机制可解释性研究人员的[综合博客文章](https://neelnanda.io/getting-started)**，从学习基础知识、成长为研究人员，到申请工作/教授职位。  
* 查看我关于**实用可解释性**的[文章](http://neelnanda.io/vision)（或[这个播客节目](https://80000hours.org/podcast/episodes/neel-nanda-mechanistic-interpretability/)）以了解我当前的研究方法  
* 排名前**约34名**的候选人将参加**为期5周的付费在线[探索阶段](#what-should-i-expect-from-the-exploration-phase?)**（**2月2日** - **3月6日**），最后以两人一组进行为期2周的研究冲刺。  
  * 预期为非结构化、自主驱动的学习  
  * **前3周兼职，最后2周全职**  
* 探索阶段中**约8名**冲刺项目最好的候选人将进入研究阶段，这是一个**为期12周的付费**和**线下**项目（**6月1日** - **8月21日**）  
  * 典型学者至少发表一篇[**共同第一作者论文**](#what-work-have-past-scholars-done?)，发表在顶级ML会议。我与每对学者每周有1.5小时的检查会议  
  * 大多数探索阶段的候选人**不会进入研究阶段**  
  * 注意研究阶段前有**3个月的间隔**。你可以在这期间与我一起做研究，或休息到研究阶段开始  
* **欢迎所有背景和经验水平** - 我想与最有潜力的人合作，而不仅仅是那些履历最好的人！  
  * 我这样设计流程是为了使其具有择优性，能够**识别有潜力但没有经验的人**。  
  * 过去的学者包括教授、没有机制可解释性经验的本科生、初创公司创始人、没有研究经验的软件工程师，以及拥有多篇优秀机制可解释性论文的研究人员

## 目录

[关键信息](#key-details)

[常见问题](#faq)

[申请任务详情]()

[如何在20小时内制作一份好的申请]()

[好的申请是什么样的？]()

[推荐的研究问题]()

[常见问题（扩展版）]()

## 关键信息 {#key-details}

* **申请任务**：花费**约16小时**（**最多20小时**）尝试在你选择的机制可解释性问题上**取得研究进展**。  
  * 通过[此表格](https://forms.matsprogram.org/neel10)**提交**，截止日期为12月23日星期二太平洋时间晚上11:59  
    * 注意：我知道你们中的一些人很忙，只能在假期期间完成一份好的申请，所以12月23日可能太早了。我将接受**延迟申请直到1月2日**，但无法保证在1月12日之前回复你。  
      * 如果你想提交延迟申请，请填写[此表格](https://forms.gle/VxUvBTcRAnnvc1YU7)说明你申请延期的原因。  
  * 请提交一份[**研究报告**和**执行摘要**](#application-format)，向我展示你在问题上取得的**进展**和**学到的内容**。  
    * 我重视**沟通能力**，不要匆忙完成报告！[时间限制](#defining-the-20+2-hour-time-limit)为执行摘要**额外提供最多2小时**。  
    * 请参阅成功的过往报告示例[此处](#examples-of-past-applications)  
  * 请参阅关于[如何完成申请](#how-to-produce-a-good-application-in-20-hours)、[如何在研究中使用LLM](#guidance-on-using-llms)、[推荐资源](#useful-resources)和[我如何评估申请](#how-are-applications-evaluated?)的**建议**  
    * 你可以在此之前花任意时间进行一般性学习。  
  * 我的**研究兴趣已经改变**了很多，与之前的一些工作相比，我在[此处](#how-my-research-interests-have-changed)详细说明了这些变化，并在[此处](#suggested-research-problems)提供了我目前感兴趣的问题的长列表。  
  * 我接受提交**现有的机制可解释性工作**，但会以更高的标准评估（[更多信息](#can-i-submit-mech-interp-research-i've-already-done?)）  
  * 如果你之前申请过，[请参阅此处](#what's-changed-from-mats-8.0?)了解**变更**摘要  
* **关键日期**：  
  * 申请截止日期**12月23日**  
  * 结果公布**1月12日**  
  * 探索阶段**2月2日 - 3月6日**（面向排名前**约34名**候选人的**5周在线**项目）  
  * 研究阶段决定**3月12日**  
  * 研究阶段**6月1日 - 8月21日**（面向排名前**约8名**候选人的**12周线下**项目）  
* **欢迎所有经验水平**：我想与最有潜力的人合作，而不是那些纸上看起来最好的人。[^1]  
  * 在MATS 8.0（我最近完成的队列）中，**我的8名学者中有5名**之前**只有很少的机制可解释性经验**，但表现非常出色 - 到项目进行到一半时，他们中的一些人已经：  
    * 帮助[**理解**](https://arxiv.org/abs/2506.11618)[**涌现**](https://arxiv.org/abs/2506.11613)[**错位**](https://www.alignmentforum.org/posts/gLDSqQm8pwNiq7qst/narrow-misalignment-is-hard-emergent-misalignment-is-easy)（即为什么[训练模型编写有bug的代码会使其变成纳粹](https://www.emergent-misalignment.com/)），并接受了**[MIT科技评论](https://www.technologyreview.com/2025/06/18/1119042/openai-can-rehabilitate-ai-models-that-develop-a-bad-boy-persona/)**的采访  
    * 探索了[**解释**](http://x.com/paulcbogdan/status/1938287361525436864)[**推理**](https://arxiv.org/abs/2506.19143)[**模型**](https://www.thought-anchors.com/)的新范式  
  * 在另一个极端，我也有学者**已经拥有多篇优秀的机制可解释性论文**，如[**Arthur Conmy**](https://scholar.google.com/citations?user=n4HIyXQAAAAJ&hl=en&oi=ao)和[**Josh Engels**](https://scholar.google.com/citations?user=yVPnVK8AAAAJ&hl=en&oi=ao)，他们说[我仍然增加了相当多的价值](#how-does-a-research-supervisor-add-value?)。

![][image1]

*我在NeurIPS 2025的MATS校友聚会 - 20位校友在同一地点！*

## 常见问题 {#faq}

### 为什么你可能想申请？

* 我的核心目标是教你**如何做优秀的机制可解释性研究**。  
* 我负责Google DeepMind的机制可解释性团队，在[研究指导方面有丰富经验](https://scholar.google.com/citations?user=GLnX3MkAAAAJ&hl=en&oi=ao)。在过去3年中，我**指导了50名初级研究人员**并**监督了30+篇MATS论文**，以及15篇顶级会议论文[^2]。  
* 该项目经常帮助学者进入**机制可解释性职业**  
  * 现在有七人在**前沿AGI实验室**从事可解释性研究，包括[Arthur Conmy](https://scholar.google.com/citations?user=n4HIyXQAAAAJ)，他为我工作，**领导**GDM [**应用可解释性团队**](https://www.alignmentforum.org/posts/aG9e5tHfHmBnDqrDy/the-gdm-agi-safety-alignment-team-is-hiring-for-applied)。  
  * 两位校友在英国政府的AI安全研究所**领导研究团队**  
* 过去的学者在项目本身中也做了出色的研究，即使是那些完全不了解机制可解释性的人！一些亮点：  
  * 展示[开源LLM可以通过线性代数廉价地被越狱](https://arxiv.org/abs/2406.11717)，通过消除拒绝方向  
    * 这激发了多个前沿实验室的项目，包括一篇关于修复它的[Meta论文](https://arxiv.org/abs/2409.20089)。  
  * [一篇ICLR口头报告](https://arxiv.org/abs/2411.14257)使用稀疏自编码器解释幻觉，并展示模型可以"识别"它们知道事实的实体。  
  * 使用可解释性[塑造模型如何泛化](https://arxiv.org/abs/2507.16795)而不改变任何数据，防止[涌现错位](https://www.emergent-misalignment.com/)  
  * [第一篇关于转码器的论文](https://arxiv.org/abs/2406.11944)，比Anthropic关于转码器的[著名](https://transformer-circuits.pub/2025/attribution-graphs/methods.html)[论文](https://transformer-circuits.pub/2025/attribution-graphs/biology.html)早九个月。  
  * 探索[稀疏自编码器中的基本问题](https://arxiv.org/abs/2502.04878)的工作和[创建最先进方法的后续工作，这些方法（大部分）修复了这些问题](https://arxiv.org/abs/2503.17547)。

### 为什么这个申请需要这么多努力？

* 我非常关心**择优性**。这种方式让我能找到最好的申请人，而不仅仅是那些纸上看起来不错的人。我尽力评估你的潜力，而不仅仅是你已经做过的事情（尽管这仍然非常嘈杂！）  
* 我也试图设计这个申请流程，使花时间在上面**无论结果如何都很有用** - 我不想浪费你12+小时的时间！  
* 我认为这是做研究的相当现实的**模拟**，特别是如果你以前没有做过可解释性研究。候选人经常学到很多东西，并对他们能完成的工作量感到惊讶。  
  * 我有时听到不成功的申请人说，他们非常享受申请过程，以至于说服他们追求研究职业！  
  * 如果你不确定是否对做机制可解释性感兴趣，我鼓励你尝试申请！我认为你会从申请中学到很多关于它是否适合你的信息。

### 我在申请中寻找什么？

* 我理想的申请是**能教给我新东西的**。  
  * 这看起来像是识别一个可解释性假设，收集支持和反对它的证据，并清楚地写出证据和分析。  
* 我重视清晰的写作、良好的品味（即选择有趣的问题并做出好的决定）、技术技能、寻求真理、怀疑主义和实用主义  
* 请参阅[此标签页]()中的更详细解释以及过往示例

### 项目中会发生什么？

* 排名前**约34名**的候选人将参加**为期5周的在线探索阶段**2月2日 - 3月6日  
  * **最后两周**（**全职**）用于以两人一组进行**研究冲刺**。进入研究阶段的录取主要基于冲刺表现。  
  * **前3周**（**兼职**）是**准备阶段**。这意味着为冲刺做准备：自主驱动的技能提升，与其他学者一起做几个日期的迷你研究项目，参加讲座/会议，阅读论文等。你如何花费时间由你决定  
  * 更多信息[此处](#what-should-i-expect-from-the-exploration-phase?)  
* 探索阶段中排名前**约8名**的候选人将在伯克利参加**为期12周的线下研究阶段**6月1日 - 8月21日  
  * 学者们两人一组撰写机制可解释性论文，我每周有**1.5小时**的检查会议和一些Slack支持  
  * 约所有最近的学者都将其作为共同第一作者论文发表在**顶级ML会议**（NeurIPS/ICLR/ICML） - 请参阅[下面的过往工作列表](#what-work-have-past-scholars-done?)  
* 研究阶段的参与者经常进行可选的**3-12个月延期**，以完成他们的论文，有时发表第二篇。  
* 所有阶段都包括**津贴**：5周探索阶段$4.2K，12周研究阶段$14.4K。研究阶段提供住房支持  
* 更多信息请访问[matsprogram.org](http://matsprogram.org)

### 如果我没有进入研究阶段会怎样？

* 虽然不幸的是，大多数探索阶段的候选人没有进入研究阶段，但我设计探索阶段是为了**本身就有价值的体验**，并教授有用的研究技能。  
  * 中位数参与者将其评为**1.5x-2.5x**的反事实时间使用。  
* 在MATS 8.0和9.0中：  
  * 至少7名仅探索阶段的学者**找到了其他MATS导师**作为参与的结果  
  * 我帮助至少**8-10名仅探索阶段**的学者**撰写论文**，基于他们的冲刺项目（[1](https://arxiv.org/abs/2505.14352) [2](https://aclanthology.org/anthology-files/anthology-files/pdf/findings/2025.findings-emnlp.1012.pdf) [3](https://arxiv.org/abs/2508.21258) [4](https://arxiv.org/abs/2507.12638) [5](https://arxiv.org/abs/2507.08218)）  
* 欢迎候选人在下一批中再次尝试

### 为什么*不应该*申请？

* 显然，申请需要一些时间！如果听起来不有趣，你可能不应该做。  
* 项目的探索阶段相当竞争激烈，有些人觉得压力很大  
  * 一般来说，参与者似乎很友好和合作，特别是因为你想组建团队，但意识到你的机会可能对某些人来说压力很大  
* 大多数探索阶段的活动发生在英国时间下午5点-8点之间，这对亚洲时区的人来说效果很差。但活动对于有价值的探索阶段来说不是必需的！  
* 探索阶段非常自主驱动和非结构化 - 我提供良好的机会、资源、建议等，你们都可以作为协作者互相帮助，但最终只有我一个人和30+个你们。你投入什么就得到什么，需要决定如何花费时间。这对某些人很有效，对其他人则不太好  
* 如果你有全职工作/否则非常忙碌，你可能发现很难为探索阶段腾出时间。

### 我应该如何选择问题？

* 我对任何显示强大研究技能的申请都持开放态度，但会对那些符合我研究兴趣的申请更感兴趣  
* **我的研究兴趣已经改变**了很多，与过去的一些工作相比 - [下面有更多细节](#how-my-research-interests-have-changed)，但简而言之，我现在对雄心勃勃的可解释性（即完全逆向工程）相当悲观，我对具有更清晰AGI安全应用的实用方法感到兴奋，如模型生物学（研究模型的定性高级属性）和应用可解释性（严格地用可解释性做有用的事情）。我仍然对基础科学感兴趣，但有更高的标准。  
  * 用新的和酷的东西让我惊喜的申请是极好的！  
* 我对最佳技术更加不可知，像稀疏自编码器这样的东西是有用的工具，但容易在更简单的方法足够或更好时浪费精力使用 - 从做显而易见的事情开始！  
* 我在[此处](#suggested-research-problems)提供了建议问题的长列表

### 我可以使用LLM吗？

* 可以。事实上，我强烈推荐！**LLM是当今重要的研究工具**，对于进入新领域的人尤其有用。  
  * 关于如何很好地使用LLM的更多建议[如下](#guidance-on-using-llms)  
* 欢迎你使用它们进行编码、写作等，无论你想要什么 - 我想评估你作为研究人员的表现如何，这包括你实际会使用的任何工具。  
  * 确保你的代码和写作高质量是你的责任。写得好的报告是受欢迎的。读起来像LLM垃圾的文档将被拒绝。  
* 我推荐使用[**Cursor**](http://cursor.com)**进行编码**（替代例如VS Code）并使用[**Claude 4.5 Sonnet**](http://claude.ai)或[**Gemini 3 Pro**](http://aistudio.google.com)**进行基于浏览器的任务**  
* 我已经编译了一个[有用的文本文件文件夹](https://drive.google.com/drive/u/0/folders/1GfrgKJwndk-twnJ8K7Ba-TE9i_8wBWAU)用于机制可解释性研究，包含大量相关文档和关键库的源代码、ARENA和关键库的教程、关键论文和我的相关博客文章。  
  * 默认情况下，只需**将[这个600k token文件](https://drive.google.com/file/d/18cF3lkU17_elUSv0zk8KSVejM1jGfNnz/view?usp=drive_link)放入Gemini的上下文窗口**，其中包含最重要的文档[^3]。

### 我需要在美国/有美国工作授权吗

* 不需要，也不需要  
* 探索阶段是远程的，可以在任何地方完成  
* 研究阶段强烈鼓励线下，但如果需要可以远程完成  
* 这是一个独立研究的教育项目，不是正式就业，这使得签证更简单。  
  * MATS不付钱给你，相反，津贴由另一个组织AI Safety Support授予  
  * 我在个人时间做这件事，与我在GDM的工作无关

### 研究导师如何增加价值？ {#how-does-a-research-supervisor-add-value?}

* 我的模型是研究需要技能组合。日常编码和执行至关重要。但也有一组更难学习的概念技能，统称为[研究品味](https://www.alignmentforum.org/posts/Ldrss6o3tiKT6NdMm/my-research-process-understanding-and-cultivating-research)。这些技能需要很长时间才能获得，因为它们有糟糕的反馈循环，但它们使用起来只需要很少的时间。  
* 我的主要作用是借给你我的研究品味并引导你自己的。这看起来像是帮助：  
  * 高级策略：选择一个好问题，知道何时从死胡同转向，或优先考虑几个有希望的方向中的哪一个。  
  * 实验设计：设计一个干净的实验来最终测试假设，思考结果的替代解释，或知道证据何时足够强。  
* 导航领域：我还可以提供相关论文或你可能遗漏的技术的指针，帮助你避免重新发明轮子。  
* 最后，有些人发现有一个事实上的轻触式管理者非常有帮助，他提供验证、问责和清晰度。  
* 过去的学者给我的反馈是，我擅长红队、产生想法，以及激励和投入他们的项目，但我期望人们能够独立工作，并且可能对反馈相当直率。

*如果你有任何问题，本文件的其他标签页没有回答，请随时[给我发邮件](mailto:neelnanda27@gmail.com)。*

# 申请任务详情

[申请格式](#application-format)

[执行摘要格式](#executive-summary-format)

[我可以提交我已经做过的机制可解释性研究吗？](#can-i-submit-mech-interp-research-i've-already-done?)

[定义20+2小时时间限制](#defining-the-20+2-hour-time-limit)

## 申请格式 {#application-format}

**格式**：申请应包括一份**总结你关键发现的google doc**，**以执行摘要开头**，理想情况下包含大量图表，并有足够的细节来理解你做了什么，而无需阅读你的代码。鼓励你包含代码，但不是必需的，我只会根据需要阅读它来更好地理解报告。**记住让任何有链接的人都能访问文档**！

### 执行摘要格式 {#executive-summary-format}

google doc的前1-3页应该是执行摘要，概述你做了什么和学到了什么。**约1页**（包括图表）很好，**最多3页**和**最多600字**。请**包含图表**！要点可以很好地工作

我会尝试阅读每份申请的执行摘要，但没有能力正确阅读每份申请，所以请确保它传达了关键信息！你大致想要传达高级要点/你认为你发现的最有趣的部分，以及你运行的关键实验的草图来验证它。

一个好的格式是包含以下部分：

* 我要解决什么问题？（以及为什么你认为它有趣的一点）  
  * 记住 - 你写的东西对你来说总是比读者清楚得多！虽然你可以假设它会被有机制可解释性研究经验的人阅读  
* 你的高级要点是什么？你项目中最有趣的部分是什么？  
* 每个关键实验一段和一张图，给出它是什么的要点，你发现了什么，以及为什么这支持你的关键要点

## 我可以提交我已经做过的机制可解释性研究吗？ {#can-i-submit-mech-interp-research-i've-already-done?}

* 如果你之前做过机制可解释性研究（（共同）第一作者[^4]论文或非第一作者但有重大贡献的论文或高努力博客文章），我接受你为该工作写执行摘要，并链接到它，而不是做正常的申请。  
  * 请包括**项目花费你多少小时的估计**  
  * 如果其他人与你一起工作，请包括你具体贡献的描述  
  * 如果它显然不是机制可解释性论文，请解释为什么你认为它显示你有相关技能。  
* 我更喜欢标准申请，我会比正常申请更严格地判断这些（你可能有更多时间），但如果你否则没有时间申请，我宁愿收到这些！  
  * 如果你甚至没有时间写执行摘要，我仍然宁愿收到你的申请而不是什么都没有，但对那些有极高的标准。  
* 如果之前的工作是你自己完成的，并且在<=20小时内，但不是*为了*申请，这显然是可以的，你可以将其视为正常的申请项目。

## 定义20+2小时时间限制 {#defining-the-20+2-hour-time-limit}

* 不计入：  
  * 一般准备（论文阅读、教程），你在决定项目之前会做的  
    * 我这里的公平原则是"任何你可以合理地自己学习机制可解释性的事情，在考虑要研究的问题之前，都是完全可以的，因为更有经验的申请人可能已经做了"  
  * 通用技术设置，如租用和设置云GPU，你需要为大多数项目做的  
  * 休息  
  * 等待事物训练的时间（假设你在此期间做其他事情，例如通宵训练SAE）  
  * 编写你对MATS申请表格的答案  
* 我认为你积极致力于项目目标的任何时间都在20小时时间限制内。这包括（但不限于）：  
  * 为你的项目编写代码  
  * 阅读论文（选择因为它们与你的项目相关）  
  * 分析数据/实验结果  
  * 思考和计划时间  
  * 编写google doc  
* 所以执行摘要不会太匆忙，你可以再花2小时。  
  * 我要求你不要编辑报告的其余部分，也不要编写任何新的实验代码，尽管欢迎你编写代码从你已经拥有的数据制作新图表/可视化，如果它有助于更好地呈现结果  
* 鼓励你使用像[Toggl](https://toggl.com/)这样的工具跟踪你的时间，并在申请文档中包含截图  
* 如果你决定你的项目注定失败，欢迎放弃并开始一个新的，并重置计时器

# 关于好申请的建议

## 

[如何在20小时内制作一份好的申请](#how-to-produce-a-good-application-in-20-hours)

[研究建议](#research-advice)

[写作建议](#writing-advice)

[使用LLM的指导](#guidance-on-using-llms)

[有用资源](#useful-resources)

[编码](#coding)

[其他资源](#other-resources)

## 如何在20小时内制作一份好的申请 {#how-to-produce-a-good-application-in-20-hours}

我建议将申请视为一个迷你研究项目。我的标准显然低于完整论文，但最好的申请看起来像小的、自包含的研究调查。它们基本上快速运行识别有趣假设、仔细测试它，然后清楚地传达结果的过程。我关于研究过程的博客文章（[探索、理解、提炼](https://www.alignmentforum.org/posts/hjMy4ZxS5ogA9cTYK/how-i-think-about-my-research-process-explore-understand)和[关键心态](https://www.alignmentforum.org/posts/cbBwwm4jW6AZctymL/my-research-process-key-mindsets-truth-seeking)）有更多细节，但我在这里总结了关键想法。

### 研究建议 {#research-advice}

一个好的研究项目有三个关键阶段：

1. **探索**：这里的目标是简单地**获得信息并建立直觉**。一个常见的错误是认为一旦你选择了一个问题，这个阶段就结束了，例如从[下面](#suggested-research-problems)的列表中选择。实际上，项目的很大一部分时间只是弄清楚发生了什么。  
   1. 你还不需要一个清晰的假设。通常最好的时间使用是让你接触大量信息的事情。  
   2. **动手实践**。尝试阅读你的数据、给你的模型有趣的提示，或查看稀疏自编码器告诉你什么。  
   3. 这并不意味着你没有计划。这意味着你的计划是最大化每单位时间的信息增益。不断问自己："**我在过去30分钟学到了什么吗？**这个方向仍然有成果吗？"  
2. **理解**：一旦你对什么可能是真的有了预感，你的目标是通过仔细的实验**说服自己它是真的**。  
   1. 保留一个运行文档，列出你的假设。在设计实验测试一个、运行它和分析结果之间交替。  
      * 将关键图表和发现放在你的文档中，随着你对假设了解更多 - 你不想忘记关键实验在哪里！  
   2. 跟踪你试图做出的声明类型至关重要。  
      * 有时你想给出存在性证明（例如，找到一个有趣现象的例子），其中挑选是可以的。  
      * 其他时候，你想论证一个方法是任务的正确做法，这需要与基线进行比较。  
   3. **常见错误**：过于兴奋并错过结果的简单替代解释；运行一堆只是模糊相关的实验，而不是努力获得**结论性证据**。  
3. **提炼**：这是你将发现转化为可读的、可以说服他人的东西的地方。这意味着清楚地和诚实地写出你的工作。  
   1. **这不是事后想法！**人们经常忽视报告，但它至关重要。**如果我不理解你做了什么，我会拒绝你的申请。**  
   2. 考虑到时间限制，你不会达到已发表论文的完整严谨性（例如，大样本量、广泛的基线）。这很好！但为你的声明提供清晰证据的原则仍然适用。  
      * 关键的是，**避免仅依赖几个精心挑选的定性示例** - 这是一个主要危险信号。  
      * 如果适用，记住与基线进行比较

### 写作建议 {#writing-advice}

有一份好的报告极其重要！我关于[撰写ML论文](https://www.alignmentforum.org/posts/eJGptPbbFPZGLpjsp/highly-opinionated-advice-on-how-to-write-ml-papers)的文章中的建议可能有用 - 显然，我不期望正式论文，但清晰沟通的原则适用。

* **专注于叙述**。不要只是转储你所有的实验。围绕你发现的一两个最有趣、最具体的见解构建你的报告。关键故事是什么？  
* **质量胜过数量**。一个有趣的发现，解释清楚和支持充分，远胜于十个肤浅的实验。  
* **展示你的工作**。解释*为什么*你运行了一个实验，而不仅仅是*你做了什么*。你在测试什么假设？可能的结果是什么？这揭示了你的思维过程。  
* **你的读者没有背景**。"透明度错觉"是一个巨大的陷阱。对你来说显而易见的事情对读者来说将是全新的。从头解释一切。定义你的术语。清楚地标记你的图表。  
* **让你的执行摘要有价值**。它需要独立存在，传达最重要的要点和你关键证据的草图。不要让我寻找要点或关键细节。好的图表在这里是一个巨大的加分项。

## 使用LLM的指导 {#guidance-on-using-llms}

强烈鼓励你在申请中使用LLM辅助 - 我想评估你在实践中做研究的表现如何，所以如果你在那里使用它，在这里也使用它！如果你不将LLM作为研究的一部分，我认为你可能做出了糟糕的决定。特别是，虽然LLM难以达到专家表现，但它们相当擅长击败新手。所以如果你试图进入一个新领域，如机制可解释性，如果你知道如何使用它们，它们可能非常有帮助[^5]。

以下是一些有效使用它们的建议 - 我为不太使用LLM的受众写了这个，但我希望即使对有经验的用户也至少有一个新颖的观点：

* **元提示**：一个好的系统提示可能非常有帮助。如果你没有强烈的偏好，或没有太多编写自己提示的经验，我建议告诉LLM你想要什么，让它为你编写提示。  
  * 如果提示没有做你想要的事情，告诉LLM这一点，给出详细反馈，并要求它重写提示以防止重复。  
  * 许多LLM提供商有一个"项目"功能，你可以在其中保存自定义提示，例如，你可以有一个用于论文摘要、启动新编码项目、关于特定库的问题（上下文中有源代码！）等  
* **上下文至关重要**：当LLM在上下文窗口中有相关信息时，它们会更有用。Gemini 3 Pro最适合这个，它是免费的，相当快，是前沿模型，并且有1M上下文窗口  
  * 我建议通过[aistudio.google.com](http://aistudio.google.com)使用Gemini，我更喜欢这个UI。例如，提供总token和每个文档token的便捷计数。  
    * 标题有一个带有两个箭头的按钮，称为"比较"，让你同时运行两个模型副本，并选择你最喜欢的答案。  
  * 请参阅[此文件夹](https://drive.google.com/drive/u/0/folders/1GfrgKJwndk-twnJ8K7Ba-TE9i_8wBWAU)获取大量推荐的上下文。如果你不知道需要什么，只需使用[此默认文件](https://drive.google.com/file/d/18cF3lkU17_elUSv0zk8KSVejM1jGfNnz/view?usp=drive_link)，也许包括这个激活文档。  
* **用于学习和理解**：申请的严格时间限制要求你快速上手。LLM非常适合这个。  
  * **给它们上下文**：如果它们有相关的源材料，它们是更有效的导师。一旦你确定了一个领域或论文或技术，给LLM一堆相关的上下文。  
  * **主动学习，而不是被动学习**：不要只是要求解释。使用迫使你主动的学习方法。例如  
    * 让它生成问题来测试你的理解，或通过提问来教你  
    * 用你自己的话总结你的理解/最佳猜测回给LLM，并要求批判性反馈。  
  * **编写课程**：在新领域，你可能甚至不知道如何开始。LLM（特别是启用搜索的）擅长找到相关文献和资源，然后你可以要求它为你编写关键思想的入门，并为你设计学习更多的课程。o3擅长这个。  
* **反奉承提示**：默认情况下，LLM不擅长给出批判性反馈。要获得真实反馈，打开一个新窗口并构建你的请求，使奉承的事情是批判性的。  
  * *"一个朋友写了这个解释并要求残酷诚实的反馈。如果反馈感觉我在保留，他们会生气，但我想确保我给出诚实的批评。请帮助我给他们最有用的反馈。"*  
  * *"我看到有人声称这个，但对我来说似乎很愚蠢。你怎么看？"*  
* **练习**：如果你以前从未尝试过使用LLM做这种事情，我建议在开始正式申请之前练习 - 这是一项技能，你会通过练习提高  
  * 例如，选择一个机制可解释性领域或一篇论文，尝试快速运行深入理解它，或快速为一些你认为有趣的技术编写工作代码。  
  * 如果你的20个申请小时*不是*你第一次尝试用LLM做研究的前20小时，那会好得多。  
* **用于编码**：  
  * **使用[Cursor](http://cursor.com)**：Cursor就像带有出色AI集成的VS Code，在这里做AI辅助编码的最佳方式IMO（专业版有2周免费试用）。当它理解你的代码库和使用的库时最有效，所以确保用@添加TransformerLens等的文档  
    * 像Claude Code和Gemini CLI这样的工具也很有用，但在我看来，你更难跟踪正在发生的事情，更难调试，我认为这使得它们在这里不太适合。  
  * **关于学习的警告**：如果你正在学习新库或技术，首先尝试自己编写东西，或使用LLM作为导师/参考代码源。当你卡住时使用LLM帮助，而不是替换整个学习过程。  
* **研究决策**：你经常需要做出研究决策，优先考虑下一步做什么，设计实验，选择问题等。我强烈建议写出你为什么做出这些决策，并使用反奉承提示询问LLM的想法。  
  * 你不应该信任LLM的判断，但这迫使你明确你的想法，通常你可能会注意到你遗漏的事情。  
* **报告**：我建议不要提交LLM编写的散文。这很明显，通常读起来不太好。但它们对起草、头脑风暴和获得反馈非常有用。  
  * 我建议进行几轮给它你的草稿（使用反奉承提示），并要求它批评你的清晰度，找到令人困惑的句子，并检查技术不准确之处。  
  * 将申请文档和[我关于论文写作的文章](https://www.alignmentforum.org/posts/eJGptPbbFPZGLpjsp/highly-opinionated-advice-on-how-to-write-ml-papers)放在上下文中  
* **作为研究工具**：LLM作为生成合成数据集的方式非常有用，作为定性评估数据的自动化方式，特别是如果给出一些标准等

## 有用资源 {#useful-resources}

请偏向于动手实践，专注于编写代码、在模型上运行实验，并从现实中获得反馈。**我建议在12-20小时中最多花5小时阅读论文和教程**。欢迎你在此之前进行一般性阅读和学习，只要它不是直接在你计划的项目上取得进展。

### 编码 {#coding}

* 如果你的项目涉及使用<=9B模型，并且你想大量使用内部结构，我建议使用[TransformerLens](https://github.com/TransformerLensOrg/TransformerLens)。  
* 否则，我建议使用[nnsight](http://nnsight.net/)，因为它性能更好，在更大的模型上工作良好 - 它只是PyTorch模型的良好包装器。  
* [ARENA教程](https://arena-chapter1-transformer-interp.streamlit.app/)很棒，既可以作为TransformerLens的介绍，也可以作为机制可解释性技术的实用编码介绍。  
  * 如果你是机制可解释性的新手并且时间有限，优先完成[第1.2章](https://arena-chapter1-transformer-interp.streamlit.app/[1.2]_Intro_to_Mech_Interp)的前3节以掌握基础知识  
  * [通用ML](https://arena-chapter0-fundamentals.streamlit.app/)的也很扎实  
* 你可以在[此文件夹](https://drive.google.com/drive/u/0/folders/1GfrgKJwndk-twnJ8K7Ba-TE9i_8wBWAU)中找到TransformerLens和nnsight的连接文档、源代码和教程，以及连接的ARENA教程，这样你就可以将它们放入LLM。  
* 如果你需要LLM API，我推荐[OpenRouter](http://openrouter.ai)，它让你基本上用相同的接口访问每个模型。  
  * 如果你想干预推理模型的思维链，例如部分填充它并重新生成其余部分，类似[思维锚点](http://thought-anchors.com)，我推荐[Nebius](http://studio.nebius.com)  
  * 要进行初始测试，通过在线聊天界面可能更容易。[poe.com](http://poe.com)是尝试大量模型的好方法  
* 关于选择什么LLM作为你的研究主题：  
  * Gemma 3和Llama 3.3是可靠的非推理模型。  
  * 如果你想使用推理模型，使用Qwen 3。如果你需要一个真正好的，试试Nemotron 49B。  
  * 除非你需要，否则不要使用专家混合模型，它们占用更多GPU内存并且很麻烦。  
  * 如果你想使用SAE，使用Gemma 2和[Gemma Scope](http://neuronpedia.org/gemma-scope)。  
* 对于编写代码，使用[Cursor](http://cursor.com)  
  * 它还可以处理新环境的大量设置成本。  
* 我建议租用和使用你自己的云GPU，而不是像Colab这样的玩具编码环境 - 如果你以前没有这样做过，请大量依赖LLM进行技术支持。[说明](https://arena-chapter1-transformer-interp.streamlit.app/#vm-setup-instructions)  
  * 要租用GPU，我推荐[runpod.io](http://runpod.io)如果成本是约束，[vast.ai](http://vast.ai)是最便宜的提供商[^6]

### 其他资源 {#other-resources}

* [我的机制可解释性阅读列表](https://www.alignmentforum.org/posts/NfFST5Mio7BCAQHPA/an-extremely-opinionated-annotated-list-of-my-favourite)用于关键论文概述（有点过时，唉）  
* [Ferrando et al](https://arxiv.org/abs/2405.00208)是关键技术的好概述  
  * 要关注的关键可解释性技术：直接logit归因、激活补丁、最大激活数据集示例、线性探针、转向向量、[稀疏自编码器](http://neuronpedia.org/gemma-scope)  
  * 关键黑盒技术：提示LLM、微调（包括LoRA）。基线很重要！  
    * 好的测试 - 你理解为什么[token强制](https://arxiv.org/abs/2312.12321)[有效且难以修复](https://arxiv.org/abs/2406.05946)吗？  
* 3Blue1Brown的[ML视频](https://www.youtube.com/watch?v=aircAruvnKk&list=PLZHQObOWTQDNU6R1_67000Dx_ZCJB-3pi)很精彩，现在涵盖transformer  
* 我的[youtube教程](https://www.youtube.com/@neelnanda2469)，特别是我的[transformer介绍](https://www.youtube.com/watch?v=bOYE6E8JrtU&list=PL7m7hLIqA0hoIUPhC26ASCVs_VrqcDpAz&pp=gAQB)、我的[研究流](https://www.youtube.com/watch?v=LP_NTmMvp10&list=PL7m7hLIqA0hr4dVOgjNwP2zjQGVHKeB7T&pp=gAQB)和我的[关于思维模型的演讲](https://www.youtube.com/watch?v=XYSKd4dOT3Y)  
  * 我关于[不同研究哲学](https://www.youtube.com/watch?v=_KoUcwCoID4)的演讲可能有助于你更好地了解该领域和各种分歧  
* 数学基础 - 你主要需要的是强大的线性代数，以及一些概率、信息论、向量微积分和优化。ML在概念上相当简单  
  * 3Blue1Brown的[线性代数系列](https://www.youtube.com/watch?v=fNk_zzaMoSs&list=PLZHQObOWTQDPD3MizzM2xVFitgF8hE_ab)很棒  
  * 对于其余部分，让LLM用苏格拉底方法教你并测试你的问题。  
* 对于任何使用SAE的工作：  
  * [ARENA SAE教程](https://arena-chapter1-transformer-interp.streamlit.app/[1.3.2]_Interpretability_with_SAEs)（警告：它很长！你应该跳过）  
  * [Gemma Scope](http://huggingface.co/google/gemma-scope)，我的团队在Gemma 2的每一层和子层上制作的高质量开放权重SAE  
  * [Neuronpedia](http://neuronpedia.org/)，一个优秀的在线工具，用于查找开源SAE中不同潜在变量（也称为特征）的解释，运行  
    * 他们的[Gemma Scope演示](https://www.neuronpedia.org/gemma-scope)是如果你对SAE不熟悉的好起点  
    * 他们还有一个[API](https://www.neuronpedia.org/api-doc)，你可以在Jupyter notebook中使用它来请求关于潜在变量的信息  
  * [字典学习库](https://github.com/saprmarks/dictionary_learning)：SAELens的更可破解和基础的替代品。如果你想对SAE训练做任何不寻常的事情，我建议使用这个而不是SAELens。  
* 如果你想了解机制可解释性，请查看[我的机器学习街谈播客采访](https://www.youtube.com/watch?v=YpFaPKOeNME)或[这个最近的文献综述/研究议程](https://arxiv.org/abs/2501.16496)[^7]  
* 我在[GDM AGI安全方法](https://arxiv.org/pdf/2504.01849#page=92.33)中写下了我对可解释性帮助AGI安全的变化理论的思考  
* [我的机制可解释性术语表](http://neelnanda.io/glossary)（有点过时，但仍然有用）

# 好的申请是什么样的？

[如何评估申请？](#how-are-applications-evaluated?)

[好的申请是什么样的？](#what-do-good-applications-look-like?)

[申请任务之外](#beyond-the-application-task)

[过往申请示例](#examples-of-past-applications)

## 如何评估申请？ {#how-are-applications-evaluated?}

### 好的申请是什么样的？ {#what-do-good-applications-look-like?}

* **清晰度**：如果我理解你在声称什么，你提供了什么证据，并认为证据支持你的结论，这立即将你置于前20%的申请人中。  
  * 向我展示足够的细节，以便我可以跟随：你是如何生成数据或选择提示的，你是如何定义指标的，你的超参数是什么，等等？如果做得好，这可以简洁 - 要点和短代码片段可以走很长的路。  
  * 我喜欢要点、好的图表、摘要、好的结构和直观的解释，以清楚地传达高级图片 - [更多建议此处](#writing-advice)。  
* **良好的品味**：你选择了一个有趣的问题，能够在其上取得进展，并产生我发现令人信服的结果。我最喜欢的申请类型是我从中学到东西的。  
  * 这不必是一个大的、雄心勃勃的声明 - 只是任何没有证据就不明显的声明。  
  * 原创性是一个很大的加分项。如果我看到一堆做极其相似事情的申请，这就不那么令人兴奋了。  
  * 与[我的研究兴趣](#how-my-research-interests-have-changed)一致是一个重要的加分项。  
* **寻求真理和怀疑主义**：最容易欺骗的人是你自己。你不断质疑你的结果，寻找替代解释，并进行健全性检查。经过良好分析的负面或不确定结果远胜于支持不佳的正面结果。（[更多建议](https://www.alignmentforum.org/s/5GT3yoYM9gRmMEKqL/p/cbBwwm4jW6AZctymL#Truth_Seeking)）  
  * 要强调的关键是自我意识和清晰度。这是一个严格的时间限制，所以你的结果会有漏洞。如果你表现出对漏洞在哪里的自我意识，哪些部分是推测性的，你接下来会调查什么，等等，这是可以的。如果你在摇摇欲坠的结果中显得过于自信，那就不行了。做出合理的声明而不是雄心勃勃的声明。  
  * 这里的一个子技能是**对细节的关注**：注意细微差别和边缘情况，并在适当的地方调查它们  
* **技术深度和实用性**：你展示了对相关工具的良好掌握，无论是编码、实验设计还是特定的可解释性方法。你表现出愿意动手编写代码和运行实验。你的写作和设计决策清楚地表明你理解你在做什么，并且有良好的动机，而不是盲目遵循配方/LLM  
  * 有用的知识领域：机制可解释性论文和技术的知识、在GPU上使用大型模型或训练SAE的能力、线性代数的流利性、对transformer的理解、对ML的理解、编码技能、设计良好交互界面和可视化的能力等。  
* **简单性**：偏向于首先尝试简单、显而易见的方法（或解释为什么它们不合适）。很容易被花哨的技术所吸引，但它们可能是一个陷阱。好的申请是实用和专注的，不是炫耀。  
  * 例如，在我团队关于为什么模型似乎表现出自我保存的[最近工作](https://www.alignmentforum.org/posts/wnzkjSmrgWZaBa2aC/self-preservation-or-instruction-ambiguity-examining-the)中，我们从阅读CoT和提示的显而易见的事情开始，然后，它只是工作了，我们停在那里并写了帖子。  
  * 项目中的每一部分复杂性都应该有原因  
* **优先级**：你很好地使用了时间，深入了一两个关键见解，而不是对许多事情肤浅（[更多建议](https://www.alignmentforum.org/s/5GT3yoYM9gRmMEKqL/p/cbBwwm4jW6AZctymL#Prioritisation)）  
  * 一个常见的错误是陷入**兔子洞** - 找到一个随机异常或细节（在我看来）不是很有趣，并花整个时间放大它。知道何时在适当的时候转向是令人印象深刻的  
    * 如果你完全改变方向（即，你的代码和发现到目前为止对新方向没有特别有帮助），我允许你重新启动20小时限制。  
  * 另一个是分散自己太薄 - 肤浅地做很多事情，但任何一个都没有足够的深度来有趣  
  * 是的，这些提示指向相反的方向。抱歉！你需要在两个极端之间取得平衡。这很难，我不期望任何人完美地做到这一点。我建议每小时或每两小时设置一个计时器，放大并询问你是否在取得进展或陷入兔子洞。  
* **生产力**：虽然做好事情比快速做事更重要，但理想是两者兼而有之。一些研究人员每单位时间比其他研究人员更有生产力，他们完成的工作要多得多。（[更多建议](https://www.alignmentforum.org/s/5GT3yoYM9gRmMEKqL/p/cbBwwm4jW6AZctymL#Moving_Fast)）  
  * 这不是关于偷工减料 - 拥有快速反馈循环、在适当的时候注意和修复低效率，以及能够在适当的时候采取行动或反思有很多技能。  
* **展示你的工作**：看到你的思维过程，理解你为什么做出你做出的决定等，这很棒。如果你的结果不确定或关键部分失败，这最重要：如果你带我了解你尝试了什么以及为什么，发生了什么，我认为你做出了合理的决定，这仍然令人印象深刻。  
  * "我卡住了所以我放弃了"和"我卡住了，所以我转向或找到了新角度，或确定了它不起作用的原因"之间的区别是巨大的。  
  * 虽然如果你*确实*有一个有趣的发现，请构建报告以强调它，不要按时间顺序！  
* **热情**和**好奇心**：机制可解释性可能很难、令人困惑和沮丧，或者它可能令人着迷、令人兴奋和诱人。你对它的感受在这里是一个很大的输入，关于你在研究中有多好以及你有多大的乐趣。核心研究技能是跟随你的好奇心（并学习研究品味以对富有成效的事情感到好奇！）  
  * 我知道这很容易伪造，很难从申请中判断，所以我不在这里给予高权重  
  * 但一般来说，读起来有趣的申请会获得加分！

### 申请任务之外 {#beyond-the-application-task}

我根据[上述标准](#what-do-good-applications-look-like?)评估申请任务，并根据我的直觉"我从阅读这个中学到了什么有趣的东西吗？"一个好的申请任务足以被接受，无论你的背景如何。

除此之外，我尽力全面评估申请 - 我想了解谁能够做优秀的机制可解释性研究。自然，之前良好的机制可解释性工作的例子是强有力的证据。除此之外，很难学到太多，但我可以获得一些信号来帮助打破平局。这些*可以*是可读的证书，但不总是。一篇有洞察力的Arxiv论文比我发现不有趣的NeurIPS口头报告要好得多的证据。

我也对非标准证书感到兴奋。在申请表中，我问："1-3个证据表明你能够在项目中做好研究？"这是你突出以下内容的机会：

* 你构建的流行开源项目。  
* 你创立的初创公司。  
* 你特别引以为豪的博客文章。  
* 你在工作或课堂项目中做的有影响力的事情。  
* 我在写这个列表时没有想到的有趣的东西！

如果你做了很酷的事情，并且你认为一个合理的人在听到后会积极更新，请提及它并解释它的相关性！

我不太关心先验知识 - 如果你足够好做一个体面的申请任务，对我来说就足够了。机制可解释性是一个年轻领域，所以不需要很长时间就能学到足够的知识来做原创研究，特别是有了现代LLM和我来帮助你优先考虑。拥有机制可解释性、ML或数学的经验会有所帮助，特别是具有良好的线性代数直觉，以及基本的编码或ML经验，但这不是必需的。

**注意**：我可能使用LLM帮助我进行申请审查，但我将对每份申请做出最终决定。其他MATS导师将有自己的政策。

## 常见错误 {#common-mistakes}

我看到的一些常见错误可能真的会损害申请的机会：

* 怀疑主义：  
  * 不承认结果的局限性（更糟糕的是，试图假装负面结果是正面的 - 负面结果是可以的！对它们撒谎不是）  
    * 相关：试图夸大他们的结果，使它们看起来比实际更有趣。只要诚实！我能看出来  
  * 不考虑结果可能为假的方式并进行健全性检查。关于申请的一个真正*积极*的迹象是，当我想出一种结果可能为假的方式，然后发现你已经检查过了！  
  * 过度复杂化事情 - 例如，对某些现象有超级复杂的假设，而不检查一个真正简单的假设。或者尝试一个非常高努力的方法，而不尝试像提示、阅读思维链或训练线性探针这样简单的事情  
    * 以开放的心态开始 -   
  * 试图调查某些现象而不检查它是否真的存在，例如GPT-2中的心理理论  
    * 相关：使用一个对任务来说太愚蠢的模型。此时在你的申请中使用GPT-2没有充分的理由  
  * 不看你的数据 - 阅读一些数据点！与你的模型对话！如果某些东西看起来奇怪，仔细看！这里几乎总是有值得学习的东西，但这个关键步骤经常被忽视（包括专业研究人员）  
* 问题选择：  
  * 选择一个无趣的问题，例如既相当不雄心勃勃*又*与[我的研究兴趣领域](#suggested-research-problems)无关的东西，如对稀疏自编码器的增量改进，或将IOI风格的电路发现应用于随机问题  
    * 一个警告信号是有特定宠物兴趣的候选人。如果你例如对AI的医学应用非常兴奋，欢迎你在这个上做一个项目，但很有可能你做一个*只有*对AI医学应用感兴趣的人觉得有趣的项目  
  * 选择一个真的远离我兴趣的问题，例如完全理论的东西，或只涉及微小玩具模型的东西  
  * 选择一个真的没有意义的问题  
  * 选择一个超级雄心勃勃或概念上混乱的问题，并变得非常困惑  
* 策略：  
  * 意识到项目可能在中途注定失败，只是继续项目而不是尝试转向。知道何时放弃是一项关键的研究技能！  
    * 如果你完全改变项目方向，欢迎重置20小时时间限制  
* 杂项：  
  * 糟糕的写作 - 如果我在申请表/执行摘要中无法理解你的摘要，我可能没有时间破译你的研究报告并弄清楚这里是否有有趣的东西。相反，良好的沟通技能是一个很大的加分项。我为什么给报告额外2小时是有原因的！  
  * 提交完全由LLM编写的申请，关于编造的实验（请不要这样做……）

## 过往申请示例 {#examples-of-past-applications}

以下是一些成功的过往申请人的示例，他们友好地提供了他们的申请公开分享。每个都有我笔记的轻微编辑的LLM摘要，让你了解我在寻找什么以及我在审查申请时在想什么。

[R1 Distill Diffing (MATS 8.0)](https://docs.google.com/document/d/1_-zmL_8xm-jypTqei0yU7NwrpFv2H-loiwRGxwpn6l4/edit?tab=t.0)  
**项目**：训练一个转码器来区分Qwen-Math模型及其R1蒸馏，发现R1蒸馏采用了比基础模型更"非正式推理"的风格。  
**评估**：该项目非常有成效，通过创建新数据集并在主要方法失败时创造性地使用LLM来找到模式，显示了良好的优先级和实用主义，尽管它在如何定义模型特定潜在变量方面存在概念错误。  
**决定**：这是边界接受；虽然项目有关键技术缺陷，但强大的实用主义、生产力和尽管挫折仍能提取有趣定性见解的能力显示了强大的研究潜力。  
（注意：尽管是边界接受，这位学者随后进入了研究阶段并一直表现很好 - 申请过程真的很嘈杂！）

[Empathic Machines (MATS 8.0)](https://crawling-opossum-1a2.notion.site/Empathic-machines-1a44cd7fb1b780539302c6c50a5ca80c)  
**项目**：AI是否表示用户的情绪状态，我们能否通过用这些转向来因果影响其行为？在玩具合成数据集上显示这对简单情绪有效。  
**评估**：一个可爱的小想法 - 执行良好，但我期望它有效，结论的强度本质上受到数据质量的限制，所以我没有从中学到太多。值得注意的是，写得很好，呈现得很好，这很容易理解。  
**决定**：边界接受 - 尽管有强烈的局限性，他们确实找到了一些令人信服的发现，很好地传达了它们，并显示了对局限性的良好自我意识以及如何扩展它。

[What Impacts CoT Faithfulness (MATS 8.0)](https://docs.google.com/document/d/11U0Mg2boJSCp8GVc15mhvxW0Kg23b6my8NN5oAv4vM0/edit?tab=t.0)  
**项目**：该项目调查了影响思维链忠实度的几个因素，发现多项选择题的忠实度低于开放式问题，并为nostalgebraist的自我纠正假设提供了证据。  
**评估**：这是一个优先级良好的项目，在选择有趣问题方面显示了良好的品味，很好地建立在现有工作上，做出了合理的决定，并怀疑地测试了关键假设。它是纯粹的行为性的，而大多数申请是机制性的，机制性工作更慢，所以我期望从强申请中获得更多输出。写作难以理解，倾向于为读者假设太多背景。  
**决定**：在边界接受的高端 - 他们在一个选择良好的问题上找到了一些见解，但沟通和输出量本可以更好。

["Wait", backtracking in CoTs of reasoning models *is* intentional (MATS 8.0)](https://docs.google.com/document/d/1wX5rpAXc5VrOxZ9hvfTd_1g3UifXTzrUUg8ie3SQQqk/edit?tab=t.0#heading=h.mfdxfkjn7xkt)  
**项目**：推理模型的思维链中的回溯是有意的行为吗？他们通过黑盒分析发现它不是随机的，然后使用SAE来识别与其相关的潜在方向。  
**评估**：该项目非常有成效，通过用多种方法解决问题，从大规模干预到训练SAE，展示了强大的实用主义和技术深度。  
**决定**：这是边界接受的高端 - 这是一个执行良好且称职的调查，尝试了许多明智的事情，但发现只是确认了一个合理的假设，并且太广泛，没有时间深入研究机制性发现并澄清发生了什么。  
注意：我将此提升为接受，因为我对候选人的资料印象深刻，他们只在几周前发现了机制可解释性，但做了大量自学，展示了主动性和能动性以及真正的动机，这表明了高潜力。他们通过其他一些成就进一步展示了令人印象深刻的能动性，如创立初创公司，以及制作广泛使用的软件片段的副项目（这位学者随后进入了研究阶段并表现很好，所以这是一个准确的预测！）

[R1D1 - Is Reasoning in Language Models Mediated by a Single Direction (MATS 8.0)](https://docs.google.com/document/d/1OiqmJ36EgBgzy5sR4YEFrn4WFXEQFmZ0oc5t8579ysE/edit?tab=t.0#heading=h.ljkfgfirrgkt)  
**项目**：该项目调查是否可以在Llama-3 8B及其R1蒸馏之间的语言模型的激活空间中识别"推理方向"。它发现了一个可以抑制或增强推理的方向。  
**评估**：核心想法不是超级原创，但这是一个执行良好且具有真正有趣结果的明智想法，显示了良好的品味和能力。他们在初始假设失败后转向时显示了实用主义，并清楚地传达了这一点。虽然概念分析有点有限，但项目成功地教给了我一些新东西。（好标题的加分项）  
**决定**：接受。该项目是一个强有力的申请：执行良好、范围良好、实用、沟通清楚，并教给了我一些东西。

[SAE Equations (MATS 6.0)](https://docs.google.com/document/d/1lSv_zEDef5-Lg-xsMuCXqN07Dj0dO1TIVMOo9PH9KhM/edit?tab=t.0)  
**项目**：设计一个算法来找到具有算术关系的SAE潜在变量，类似king + woman - man = queen。找到了一些非常酷的例子  
**评估**：不是最有成效的申请，但一个不错且有品味的问题选择，动机良好，执行良好，并找到了一些可爱的定性结果  
**决定**：接受 - 显示了良好的品味、做研究的能力，我学到了一些新东西，尽管更多输出会使它更强。  
（注意：虽然我现在对SAE不太感兴趣，但我认为这里展示的风格和研究技能仍然存在，这可能仍然会在今天通过）

# 推荐的研究问题

## 

[我的研究兴趣如何改变](#how-my-research-interests-have-changed)

[建议的研究问题](#suggested-research-problems)

[模型生物学](#model-biology)

[理解奇怪行为](#understanding-weird-behaviour)

[推理模型](#reasoning-models)

[有趣现象](#interesting-phenomena)

[电路分析](#circuit-analysis)

[客观测量可解释性](#objectively-measuring-interpretability)

[应用可解释性](#applied-interpretability)

[基础科学](#basic-science)

[新颖性](#novelty)

[其他研究哲学更新](#heading=h.web818qn8al1)

## 我的研究兴趣如何改变 {#how-my-research-interests-have-changed}

自2024年初以来，我的研究兴趣和观点已经改变了很多。这意味着我过去做过工作的许多主题不一定是我最兴奋监督未来工作的主题，这经常被申请人误解。为了帮助你选择一个我可能感兴趣的问题，请参阅我关于[可解释性的实用愿景](http://neelnanda.io/vision)的博客文章，以及这篇关于[我认为它可以帮助AGI顺利发展的方式](http://neelnanda.io/agenda)的文章

其他一些资源：

* 我的[80,000小时播客采访](https://80000hours.org/podcast/episodes/neel-nanda-mechanistic-interpretability/)是关于我的观点以及它们为什么改变的好来源（尽管我自那以后对它们进行了一些改进）  
* 我向我的MATS 9.0学者做的一系列演讲，关于：  
  * [机制可解释性中现在重要的事情](https://www.youtube.com/watch?v=XZX_CFfVgIc)的大图  
  * 我如何看待[机制可解释性帮助使AGI安全](https://www.youtube.com/watch?v=XB_7OVLxkpU)  
  * [机制可解释性中稀疏自编码器研究的故事](https://www.youtube.com/watch?v=Tgq7E4YcPKQ)以及我在这里犯的错误，这引发了我许多观点的改变

如果你听到所有这些，然后说"这听起来真的很无聊，我不再感兴趣"，那很好 - 我们可能不会是一个好的匹配！现在学习这个比以后好得多。有[其他MATS导师](http://matsprogram.org)将很快开放申请，希望其中有一个更符合你正在寻找的。

## 建议的研究问题 {#suggested-research-problems}

以下是我会感到兴奋的一堆建议。强有力的申请经常在这些想法上即兴发挥 - 提出自己的方法，但沿着与下面类似的主题。你不应该感到受限于此列表上的问题，但希望它可以作为我兴奋看到的问题类型的指导。

**警告**：下面的想法**没有**被过滤为"我确信有人可以在20小时内取得进展"。选择一些你有想法如何开始的东西（或在该领域阅读一点，尝试生成想法和草图计划，然后再选择问题）

我大致将我的兴趣分为三个领域：**应用可解释性**、**模型生物学**和**基础科学**。

### 模型生物学 {#model-biology}

这是关于研究模型行为的高级、定性属性，将其视为我们试图理解的生物有机体。这对于奇怪的、涌现的或与安全相关的现象尤其有趣。

#### 理解奇怪行为 {#understanding-weird-behaviour}

* **深入神秘行为**：选择一个奇怪的模型行为（例如，模型似乎表现出自我保存、[敲诈](https://www.anthropic.com/research/agentic-misalignment)或[假装对齐](https://arxiv.org/abs/2412.14093)）并尝试理解发生了什么。  
  * **提示**：从显示行为的最小模型开始。  
  * 我在GDM团队的[示例工作](https://www.alignmentforum.org/posts/wnzkjSmrgWZaBa2aC/self-preservation-or-instruction-ambiguity-examining-the)：我们分析了为什么模型似乎阻止你关闭它们（在之前的演示中），发现模型实际上只是困惑。我们从最简单的技术开始，阅读思维链以生成假设，并通过改变提示来因果测试它们，这很有效。记住从简单开始！  
* **调试**：你能拿一个模型行为示例，其中它的行为方式不符合预期，理解发生了什么，并理想地修复它吗？例如[为什么它认为9.8 > 9.11](https://transluce.org/observability-interface)

#### 推理模型 {#reasoning-models}

* **思维链忠实度**：一个明显的安全策略是"让我们只阅读思维链，看看它是否认为任何可疑的东西"。你能找到支持或反对这有效的证据吗？  
  * 你能通过研究不忠实思维链的例子学到什么吗？例如来自[Arcuschin et al](https://arxiv.org/abs/2503.08679)或[Chen et al](https://assets.anthropic.com/m/71876fabef0f0ed4/original/reasoning_models_paper.pdf)  
  * 你能创建模型确实使用可疑推理的情况吗？例如，通过训练CoT被扭曲，或告诉它它的思维链正在被监控 - 它是否在没有可疑推理的情况下做坏事？行为能有多复杂？  
    * 我很想看到有人使用[合成文档微调](https://alignment.anthropic.com/2025/modifying-beliefs-via-sdf/)来训练模型相信它应该有不忠实的思维链，并看看我们是否能解释发生了什么。  
  * 你能设计好的监控器或指标来判断思维链是否在告诉我们我们认为的东西吗？  
  * 我们能判断CoT何时对模型给出答案在因果上重要吗？  
    * 这是一个微妙的概念 - 模型可能有一个因果上无关的CoT，给出相同的答案。并且[编辑CoT使模型偏离分布，这可能因无关原因改变其答案](https://www.alignmentforum.org/posts/HQyWGE2BummDCc2Cx/the-case-for-cot-unfaithfulness-is-overstated)  
  * 什么因素导致不同形式的"不忠实"CoT？我们能区分它们吗？  
    * 故意合理化预定的答案（[Arcuschin et al.](https://arxiv.org/abs/2503.08679)，[Lindsey et al.](https://transformer-circuits.pub/2025/attribution-graphs/biology.html)）  
    * 模型因为提示而改变答案但不承认（[Chen et al.](https://assets.anthropic.com/m/71876fabef0f0ed4/original/reasoning_models_paper.pdf)）  
    * 模型在数学问题中卡住后采取逻辑捷径，声称它们已经实现了有效的"证明"（[Arcuschin et al.](https://arxiv.org/abs/2503.08679)）  
    * 模型给出合理的思维链，但在最后一刻"翻转"到不同的最终答案（[Arcuschin et al.](https://arxiv.org/abs/2503.08679)）  
* **思维锚点**：在[Bogdan et al](http://thought-anchors.com)中，我的学者提出了机制可解释性对推理模型可能看起来的范式，我们将句子作为主要分析单位，并使用重采样等工具来理解哪些句子重要，并进行因果干预来理解句子对之间的依赖关系。你如何扩展和建立这些技术？你能通过使用它们找到任何有趣的东西吗？你能找到任何弱点或局限性吗？  
* **隐写术**：模型能在其思维链中编码信息吗？理想情况下，以一种思维链对我们仍然合理的方式，但即使在我们知道它被编码但不知道它意味着什么的方式中。你能训练一个模型具有我们不理解的推理，并使用可解释性工具来破译它吗？[相关工作](https://www.alignmentforum.org/posts/ywzLszRuGRDpabjCk/do-reasoning-models-use-their-scratchpad-like-we-do-evidence)  
  * 注意，这需要允许模型做没有思维链就无法完成的任务才能有趣。

#### 有趣现象 {#interesting-phenomena}

* **用户模型**：[Chen et al](https://arxiv.org/abs/2406.07882)显示LLM形成令人惊讶的准确和详细的用户模型，例如他们的性别、年龄、社会经济地位和教育水平，并且从很少的信息中做到这一点。他们可以用探针找到这些，并用这些转向以奇怪的方式改变模型的行为。  
  * 这太疯狂了！我们还能在这里学到什么？模型还表示关于用户的什么？这些是如何推断的？它们还如何塑造行为？  
  * LLM是否为跨轮次变化的属性形成动态用户模型，例如情绪、用户知道什么等。  
    * 作为一个延伸目标，LLM是否曾经尝试故意操纵这些？例如，检测用户何时悲伤并试图让他们快乐  
* **上下文外推理**：有时模型泛化得比预期远得多。最著名的是[涌现错位](http://emergent-misalignment.com)，其中训练模型编写不安全的代码使其变成纳粹。这是怎么回事？我学者的一些过去工作表明，这通常是学习[单个](https://arxiv.org/abs/2507.08218)[方向](https://arxiv.org/abs/2506.11618)的下游，暗示这是因为通用解决方案[更高效](https://www.alignmentforum.org/posts/gLDSqQm8pwNiq7qst/narrow-misalignment-is-hard-emergent-misalignment-is-easy)。但我们不理解很多 - 这是全部故事吗？为什么有些解决方案比其他解决方案更容易学习？这些奇怪的效果是否出现在任何实际用例中？  
  * 一个值得注意的例子是[合成文档微调](https://alignment.anthropic.com/2025/modifying-beliefs-via-sdf/)，其中在LLM生成的文档上训练，这些文档来自某个错误事实为真的世界，可以让LLM内化它并根据该错误信念的后果采取行动。这里发生了什么？这真的有效吗？它有多稳健？等等。  
* **概念表示**：如何计算和表示特定的有趣概念？  
  * 我们能训练一个[真理探针](https://arxiv.org/abs/2310.06824)，它很好地泛化到实际情况吗？  
  * [欺骗](https://arxiv.org/abs/2502.03407)探针呢？  
  * [不确定性](https://arxiv.org/abs/2406.16254)是如何表示的？  
  * 为什么会有[错位](https://arxiv.org/abs/2506.11618)[方向](https://openai.com/index/emergent-misalignment/)？  
  * 是否被[评估](https://arxiv.org/abs/2507.01786)的[意识](https://www.alignmentforum.org/posts/E3daBewppAiECN3Ao/claude-sonnet-3-7-often-knows-when-it-s-in-alignment)[如何表示](https://arxiv.org/abs/2505.14617v2)？Nemotron 49B似乎是研究这个的好模型。  
* **冲突信息**：模型如何处理指令或目标之间的冲突，或其先验知识与上下文之间的冲突？  
* **模型差异**：微调期间发生了什么变化？比较变化前后的模型（例如，聊天微调、指令微调或在虚假事实上微调）可以是隔离所学内容的强大方法 - 请参阅[我过去学者的工作](https://www.alignmentforum.org/posts/xmpauEXEerzYcJKNm/what-we-learned-trying-to-diff-base-and-chat-models-and-why)关于差异聊天微调以获得更多指针。  
  * 看到推理微调期间发生的事情可能特别有趣。Venhoff et al使用简单技术，如每token KL散度来研究高级差异，而[Ward et al](https://arxiv.org/abs/2507.12638)专注于回溯，一种特定行为。

#### 电路分析 {#circuit-analysis}

* **归因图**：[归因](https://transformer-circuits.pub/2025/attribution-graphs/methods.html)[图](https://transformer-circuits.pub/2025/attribution-graphs/biology.html)是理解模型生物学的有用技术吗？你能在[Neuronpedia](https://www.neuronpedia.org/gemma-2-2b/graph)上的图中找到任何有趣的东西吗？你能找到克服它们一些[局限性](https://transformer-circuits.pub/2025/attribution-graphs/methods.html#limitations-faithfulness)的方法吗？你能用它们找到用更简单的技术（如猜测和检查）无法找到的东西吗？  
  * 精确度有多重要？归因图方法相对于例如提示的一个值得注意的后果是，它可以找到更细致和详细的假设，如[Lindsey et al](https://transformer-circuits.pub/2025/attribution-graphs/biology.html#dives-addition)中的加法分析。有这种精确度重要的任务吗？  
* **基线**：有一堆简单的方法，基本上归结为猜测假设并检查它们。比这些方法投入了更多努力到像归因图这样的花哨技术。我们能推动它们走多远？  
  * 线性探针可以非常有效地识别模型正在表示的概念 - 我们能否自动化和扩展测试许多线性探针的过程，在所有适当的层/标记位置，对于给定任务？  
  * 扩展阅读模型思维链的过程。我们如何最好地分析和聚合它们，以寻找意外属性，跨许多提示？[Docent](https://transluce.org/introducing-docent)是这个方向的一个有趣方法。  
  * 简单地观察模型对适当提示混合的响应行为可以非常有效地推断机制假设，但做好它有艺术性。这里的最佳实践是什么样的？它们能自动化吗？  
* **自动化**：我们能否用[LLM代理](https://alignment.anthropic.com/2025/automated-auditing/)自动化完整的假设生成+验证循环？  
  * 自动化假设生成  
    * LLM能否简单地猜测任务的高级因果图？如果我们让代理迭代地选择不同的提示并阅读输出，代理能否取得更多进展  
    * LLM在解释归因图方面有多好，我们能用正确的提示和脚手架使它们有多好？  
  * 自动化验证  
    * 我们能否自动化探针的设计来测试预测特征的存在？  
    * 我们能否自动化干预实验，以及用于假设验证的合成/分布外输入？

#### 客观测量可解释性 {#objectively-measuring-interpretability}

* **引发潜在知识**：我们能否使用可解释性从模型中引发秘密知识？什么技术最有效？  
  * 在[Cywiński et al](https://arxiv.org/abs/2505.14352)中，我的学者通过在该词的描述上训练模型来教模型一个秘密词，然后用黑盒和白盒技术检索它。你能做得更好吗？（[他们的模型](https://huggingface.co/collections/bcywinski/gemma-2-9b-it-taboo-6826efbb186dfce0616dd174)）  
  * 你能创建更有趣的模型生物吗？[Marks et al](https://arxiv.org/abs/2503.10965)做了一个更雄心勃勃的版本，涉及用[合成文档](https://alignment.anthropic.com/2025/modifying-beliefs-via-sdf/)教模型虚假事实，你还能用该技术做什么？  
* **基于理解的下游任务**：除了上述之外，还有哪些其他客观任务测试我们在理解方面的成功？[Movva et al](https://arxiv.org/abs/2502.04382)。是另一个好例子。

### 应用可解释性 {#applied-interpretability}

我对找到可解释性的实用、现实世界应用的工作感到兴奋，特别是对于安全。这不仅仅是使用下游任务进行基础。关键是选择一个真正重要的问题，并展示可解释性有帮助。我发现这是一个令人兴奋的工作线，因为如果我们希望可解释性最终对使AGI安全有用，现在弄清楚如何做事似乎是重要的实践。

* **监控**：安全中一个极其重要的问题是监控：当模型运行时，查看是否存在某个概念。经典的探针技术极其便宜，并且是[前沿模型上廉价监控的SOTA](https://alignment.anthropic.com/2025/cheap-monitors/)用于检测滥用。我们还能用探针做什么？  
  * 如何改进探针？我们能否解决传统探针效果较差的情况，例如信息分布在标记之间或当有长上下文且有很多误报空间时？[Kantamneni et al](https://arxiv.org/abs/2502.16681)中的注意力头探针是一个好的起点。  
* **分析思维链（CoT）**：你能使用或分析推理模型的CoT来理解其行为，或以其他方式实现一些实际用途吗？你能通过重采样或编辑CoT来引导行为吗？  
  * 最简单的方法是阅读或让LLM阅读CoT  
  * 如果你需要更强大的技术，[Bogdan et al](http://thought-anchors.com)可能有用  
* **其他技术**：我认为可能具有有希望的实际应用的其他一些技术。  
  * [条件转向](https://arxiv.org/abs/2409.05907)：仅在探针触发时应用转向向量。这大大降低了转向的副作用。  
  * [训练数据归因](https://arxiv.org/abs/2205.11482)：一系列方法，包括影响函数，研究哪些数据点会影响模型采取特定行为更多。这里的数学声明基本上是胡说八道，但我认为能够将模型行为与数据点关联起来打开了有趣的用例，如调试或[移除噪声数据点](https://arxiv.org/abs/2002.08484)或[过滤最佳数据进行微调](https://arxiv.org/abs/2402.04333)  
    * 警告：如果你以前没有使用过TDA，这在20小时内可能不实用  
  * [消除](https://arxiv.org/abs/2406.11717)：在拒绝由单个方向介导的情况下，我的学者通过从权重中移除拒绝方向来廉价地越狱模型。"[消除](https://huggingface.co/blog/mlabonne/abliteration)"的想法还能如何应用？

### 基础科学 {#basic-science}

我通常对推进我们对可解释性关键问题理解的工作感到兴奋。这不如以前是我的重点，但我仍然对监督此类工作感到兴奋。注意，我对玩具模型、算法任务或训练期间的可解释性工作不太感兴趣，除非有一个很好的宣传。

* **理解推理模型**：产生长思维链的推理模型内部实际发生了什么？我们能否[干预](https://arxiv.org/abs/2506.18167)它们的推理过程？  
  * 编辑模型的思维链出人意料地困难，因为如果你从那时起重新生成，它们通常会立即纠正引入的任何错误。这是怎么回事？我们能阻止它吗？如果你token强制下一句，这足够吗？等等。  
  * 用RL训练的模型与从RL训练的模型蒸馏的模型相比如何？例如，比较QwQ与R1蒸馏。  
* **引导微调**：在[Casademunt et al](https://arxiv.org/abs/2507.16795)中，我的学者表明，你可以通过消除我们不希望它使用的概念来控制模型在微调后如何泛化，数据或损失零变化。他们用这个来大部分修复[涌现错位](http://emergent-misalignment.com)。这真的很酷！我们还能在哪里应用它？  
* **电路发现**：像[转码器](https://arxiv.org/abs/2406.11944)或归因图这样的工具实际上在[告诉](https://transformer-circuits.pub/2025/attribution-graphs/methods.html)[我们](https://transformer-circuits.pub/2025/attribution-graphs/biology.html)关于电路什么？它们在做我们认为它们在做的事情吗？它们遗漏了什么？  
  * [跨层转码器](https://transformer-circuits.pub/2025/attribution-graphs/methods.html)中的跨层连接有多重要？它们真正在做什么？  
* **SAE的基础科学**：  
  * 为什么学习某些概念，而不是其他概念？这如何受数据、SAE大小等影响。  
    * Scaling Monosemanticity在[这里](https://transformer-circuits.pub/2024/scaling-monosemanticity/#feature-survey-completeness)有一些很棒的初步结果，但我没有看到后续  
  * [Matryoshka SAE](https://arxiv.org/abs/2503.17547)的改进*有多大*？我们应该一直切换到使用它们，还是它们有一些缺陷？它们真正在做什么？  
* **健全性检查叠加**：  
  * 我们能找到对应于概念的"真实"方向吗？我们如何判断我们是否成功了？  
  * 我们能找到一个令人信服的叠加中表示的概念案例研究，它不能仅由一组较小的正交概念组成吗？我们对叠加真的是一个东西有多自信？  
  * 我们能找到非线性表示的例子吗？（注意：仅[找到存在于大于一维子空间中的概念](https://transformer-circuits.pub/2024/july-update/index.html#linear-representations)是不够的）

### 新颖性 {#novelty}

* **新想法**：对于任何感到雄心勃勃的人，我对任何显示对我来说是新的或我没有期望有效的可解释性想法和应用的应用印象深刻  
  * 我最喜欢的最近例子之一是在[Casademunt et al](https://arxiv.org/abs/2507.16795)中，我的学者表明可以在不改变数据的情况下引导微调。

# 常见问题（扩展版）

## 

[常见问题（扩展版）](#faq-\(extended\))

[● 什么是MATS？](#what's-mats?)

[● 我应该从探索阶段期待什么？](#what-should-i-expect-from-the-exploration-phase?)

[● 与MATS 9.0相比有什么变化？](#what's-changed-from-mats-9.0?)

[● 与MATS 8.0相比有什么变化？](#what's-changed-from-mats-8.0?)

[● 过去的学者做了什么工作？](#what-work-have-past-scholars-done?)

[● 如果我想做机制可解释性研究但没有被项目接受，我应该做什么？](#what-should-i-do-if-i-want-to-do-mech-interp-research-but-am-not-accepted-to-the-program?)

[● 如果我被你的项目接受，我开始然后退出是否重要？](#if-i-get-accepted-to-your-program,-is-it-a-big-deal-if-i-start-and-then-withdraw?)

[● 会有2026年夏季队列吗？](#will-there-be-a-summer-2026-cohort?)

[● 可以远程进行研究阶段吗？](#is-it-possible-to-do-the-research-phase-remotely?)

[● 训练和研究阶段之间有很长的间隔，我能在间隔期间做研究吗？](#there's-a-long-gap-between-the-training-and-research-phase,-can-i-do-research-in-the-gap?)

[● 如果我有全职工作，我能做探索阶段吗？](#can-i-do-the-exploration-phase-if-i-have-a-full-time-job?)

[● 谁拥有知识产权？](#who-owns-the-intellectual-property?)

## 常见问题（扩展版） {#faq-(extended)}

* #### 什么是MATS？ {#what's-mats?}

  * 简而言之，这是一个帮助对齐研究人员指导初级研究人员的项目，而无需运行自己的指导项目。请参阅[MATS网站](https://www.matsprogram.org/)了解整个项目的更多信息。其他10.0导师即将开放  
  * 每个导师对他们的流有很大的控制权，不同的流将有很大的不同体验，我建议将其视为许多不同的小指导项目，而不是一个大项目。  
    1. （特别是，大多数申请比我的快得多，我是唯一一个有探索阶段的人）  
  * 鼓励你申请任意多个导师。你将同时收到所有研究阶段的录取通知，然后可以在它们之间选择。

* #### 我应该从探索阶段期待什么？ {#what-should-i-expect-from-the-exploration-phase?}

  * **结构**：3周准备阶段：2月2日 - 2月20日和2周研究冲刺：2月23日 - 3月6日  
  * **警告**：探索阶段*不是*结构化课程。我不会告诉你该做什么。我将我的角色视为促进者 - 我尝试提供建议、良好机会和资源，并帮助你们所有人协作和互相学习。  
    1. 但现实地，我基本上独自运行这个，有30+个你们，我真的无法做一对一的时间。  
    2. 过去的学者经常评论说，即使在收到这样的警告后，他们对它是多么非结构化和自主驱动感到惊讶。  
  * 准备阶段：  
    1. 三周的教育+技能提升，[沿着这篇文章的路线](https://neelnanda.io/getting-started)。  
    2. 学者花费时间的主要事情是自主驱动的学习，如做编码教程和阅读论文，以及做迷你项目，0.5到5天的研究项目，自己或与合作伙伴一起，然后，基本上，作为冲刺的热身。  
    3. 将会有每周小组检查电话、自组织的结对编程和协作，你将能够在Slack上互相和我提问  
    4. 这是兼职的，但一些学者选择全职做。你不会根据在这里花费的时间进行评估，但我期望这对冲刺有优势。  
  * 探索阶段内容示例 - 请参阅[上次的日程表](https://docs.google.com/spreadsheets/d/17jBAt4h7cu2sWkTe23Il9qihXxip9ztTO4qUEL5lUBM/edit?gid=0#gid=0)：  
    1. 讲座，如我关于[机制可解释性大图和关键研究领域](https://www.youtube.com/watch?v=XZX_CFfVgIc&list=PL7m7hLIqA0hr-WLSuTrWgoTpPE8fznOZO)的讲座系列，或来自关键论文的作者，或关于nnsight如何工作（一个流行的机制可解释性库）等主题  
    2. 我在一个小机制可解释性问题上做[实时研究](https://www.youtube.com/watch?v=LP_NTmMvp10)，同时进行氛围编码并叙述我的思维过程  
    3. 我实时编写冲刺问题列表，并叙述我的思维过程，说明我如何分解空间，为什么我认为一个问题有趣，我会如何接近它等  
    4. 与其他参与者的社交活动  
       * 既有远程的，也有线下的，如果同一地点有足够的人！我们之前有伦敦、纽约、剑桥（美国）等  
    5. **注意**：只有我一个人和30+个你们！不幸的是，这意味着我没有能力进行1对1，主要运行小组活动。  
  * 一个为期两周的全职研究冲刺，你选择一个开放问题并尝试在其上取得进展。  
    1. 我主要根据你的研究冲刺输出来判断进入研究阶段的录取  
    2. 你将与另一位学者（你选择的）两人一组进行，尽管单独项目是可能的。  
    3. 每个团队将在冲刺结束时给我一个演示，我评估接受谁进入研究阶段。  
       * 你可以在演示结束时请求项目反馈。

* #### 与MATS 9.0相比有什么变化？ {#what's-changed-from-mats-9.0?}

  * 不多，申请过程基本未变

* #### 与MATS 8.0相比有什么变化？ {#what's-changed-from-mats-8.0?}

* 我稍微增加了[时间限制](#defining-the-20+2-hour-time-limit)（现在最多20小时，+2用于执行摘要）。  
* 我进一步远离稀疏自编码器相关项目，我相对更兴奋于模型生物学和应用可解释性项目 - 详细信息[此处](#how-my-research-interests-have-changed)  
* 推理模型可解释性取得了大量进展，我在那里有更多[项目想法](#reasoning-models)。  
* Arthur Conmy将不会帮助运行探索阶段。但他将拥有MATS学者，我可能将没有进入研究阶段的学者推荐给他和其他导师  
* 在MATS 8.0中，我尝试鼓励学者在前三周做迷你项目，基本上是小型研究冲刺（自己或与合作伙伴）。这非常成功，现在是项目的核心部分。  
* LLM在过去六个月中有了显著改进，我提供了[更详细的建议](#guidance-on-using-llms)关于使用它们的最佳方式。

* #### 过去的学者做了什么工作？ {#what-work-have-past-scholars-done?}

  * 过去学者的论文[^8]：  
    1. [Do I Know This Entity? Knowledge Awareness and Hallucinations in Language Models](https://arxiv.org/abs/2411.14257) (Javier Ferrando, Oscar Obeso, Senthooran Rajamanoharan, Neel Nanda, ICLR 2025 (Oral))  
    2. [Inference-Time Decomposition of Activations (ITDA): A Scalable Approach to Interpreting Large Language Models](https://arxiv.org/abs/2505.17769) (Patrick Leask, ICML 2025\)  
    3. [Scaling sparse feature circuit finding for in-context learning](https://arxiv.org/abs/2504.13756) (Dmitrii Kharlapenko, Stepan Shabalin, ICML 2025\)  
    4. [Learning Multi-Level Features with Matryoshka Sparse Autoencoders](https://arxiv.org/abs/2503.17547) (Bart Bussmann, Noa Nabeshima, ICML 2025\)  
    5. [SAEBench: A Comprehensive Benchmark for Sparse Autoencoders in Language Model Interpretability](https://arxiv.org/abs/2503.09532) (Adam Karvonen, Can Rager ICML 2025\)  
    6. [Are Sparse Autoencoders Useful? A Case Study in Sparse Probing](https://arxiv.org/abs/2502.16681) (Subhash Kantamneni, Joshua Engels, ICML 2025\)  
    7. [Sparse Autoencoders Do Not Find Canonical Units of Analysis](https://arxiv.org/abs/2502.04878) (Patrick Leask, Bart Bussmann, ICLR 2025\)  
    8. [Towards Principled Evaluations of Sparse Autoencoders for Interpretability and Control](https://arxiv.org/abs/2405.08366) (Aleksandar Makelov, George Lange ICLR 2025\)  
    9. [Confidence Regulation Neurons in Language Models](https://arxiv.org/abs/2406.16254) (Alessandro Stolfo, Ben Wu, NeurIPS 2024\)  
    10. [Transcoders Find Interpretable LLM Feature Circuits](https://arxiv.org/abs/2406.11944) (Jacob Dunefsky, Philippe Chlenski, NeurIPS 2024\)  
    11. [Refusal in Language Models Is Mediated by a Single Direction](https://arxiv.org/abs/2406.11717) (Andy Arditi, Oscar Obeso, Aaquib Syed, NeurIPS 2024\)  
    12. [Explorations of Self-Repair in Language Models](https://arxiv.org/abs/2402.15390) (Cody Rushing, ICML 2024\)  
    13. [Is This the Subspace You Are Looking for? An Interpretability Illusion for Subspace Activation Patching](https://arxiv.org/abs/2311.17030) (Aleksandar Makelov, Georg Lange, ICLR 2024\)  
    14. [A Toy Model of Universality: Reverse Engineering How Networks Learn Group Operations](https://arxiv.org/abs/2302.03025) (Bilal Chughtai, ICML)  
    15. [Finding Neurons in a Haystack: Case Studies with Sparse Probing](https://arxiv.org/abs/2305.01610) (Wes Gurnee, TMLR)  
    16. [Interpreting Attention Layer Outputs with Sparse Autoencoders](https://arxiv.org/abs/2406.17759) (Connor Kissane, Robert Krzyzanowski, Spotlight, Mechanistic Interpretability Workshop at ICML 2024\)  
    17. [Linear Representations of Sentiment in Large Language Models](https://arxiv.org/abs/2310.15154) (Curt Tigges, Oskar Hollinsworth, BlackboxNLP)  
    18. [Copy Suppression: Comprehensively Understanding an Attention Head](https://arxiv.org/abs/2310.04625) (Callum McDougall, Arthur Conmy, Cody Rushing, BlackboxNLP)  
    19. [Training Dynamics of Contextual N-Grams in Language Models](https://arxiv.org/abs/2311.00863) (Lucia Quirke, Lovis Heindrich)  
    20. [Thought Anchors: Which LLM Reasoning Steps Matter?](https://arxiv.org/abs/2506.19143) (Paul C. Bogdan, Uzay Macar)  
    21. [Understanding Reasoning in Thinking Language Models via Steering Vectors](https://arxiv.org/abs/2506.18167) (Constantin Venhoff, Iván Arcuschin)  
    22. [How Visual Representations Map to Language Feature Space in Multimodal LLMs](https://arxiv.org/abs/2506.11976) (Constantin Venhoff, Ashkan Khakzar)  
    23. [Convergent Linear Representations of Emergent Misalignment](https://arxiv.org/abs/2506.11618) (Anna Soligo, Edward Turner)  
    24. [Model Organisms for Emergent Misalignment](https://arxiv.org/abs/2506.11613) (Edward Turner, Anna Soligo)  
    25. [Towards eliciting latent knowledge from LLMs with mechanistic interpretability](https://arxiv.org/abs/2505.14352) (Bartosz Cywiński, Emil Ryd)  
    26. [Overcoming Sparsity Artifacts in Crosscoders to Interpret Chat-Tuning](https://arxiv.org/abs/2504.02922) (Julian Minder, Clément Dumas)  
    27. [BatchTopK Sparse Autoencoders](https://arxiv.org/abs/2412.06410) (Bart Bussmann, Patrick Leask)  
    28. [Evaluating Sparse Autoencoders on Targeted Concept Erasure Tasks](https://arxiv.org/abs/2411.18895) (Adam Karvonen, Can Rager)  
  * 我帮助仅探索阶段学者的论文：  
    1. [Internal states before wait modulate reasoning patterns](https://aclanthology.org/anthology-files/anthology-files/pdf/findings/2025.findings-emnlp.1012.pdf) (Dmitrii Troitskii, Koyena Pal - 发表在EMNLP)  
    2. [Towards eliciting latent knowledge from LLMs with mechanistic interpretability](https://arxiv.org/abs/2505.14352) (Bartosz Cywiński, Emil Ryd)  
    3. [Simple Mechanistic Explanations for Out-Of-Context Reasoning](https://arxiv.org/abs/2507.08218) (Atticus Wang, Oliver Clive-Griffin)  
    4. [Reasoning-Finetuning Repurposes Latent Representations in Base Models](https://arxiv.org/abs/2507.12638) (Jake Ward, Chuqiao Lin)  
    5. [RelP: Faithful and Efficient Circuit Discovery in Language Models via Relevance Patching](https://arxiv.org/abs/2508.21258) (Farnoush Rezaei Jafari)

* #### 为什么你没有给出很多MATS 9.0的例子？

  * MATS 10.0比MATS 9.0更早开始周期，所以MATS 9.0探索阶段在11月初结束，研究阶段从2026年1月到3月运行，所以我还没有太多数据！

* #### 如果我想做机制可解释性研究但没有被项目接受，我应该做什么？ {#what-should-i-do-if-i-want-to-do-mech-interp-research-but-am-not-accepted-to-the-program?}

  * 对此感到抱歉！有更多想做机制可解释性研究的好人，但我没有能力指导。关于如何做一个好的申请项目的建议与我一般会给出的做你的第一个机制可解释性项目的建议相同。

* #### 如果我被你的项目接受，我开始然后退出是否重要？ {#if-i-get-accepted-to-your-program,-is-it-a-big-deal-if-i-start-and-then-withdraw?}

  * 这对我来说完全可以！在过去，大约六分之一做培训项目的人因各种个人原因退出。从我的角度来看这很好，如果有疑问，请申请，只需在你的申请中包含一个说明。  
  * 探索阶段的重点是对学者有用和教育，而不是为我增加价值 - 如果它对你没有帮助，或者出现了更好的选择，请退出！我希望你为自己做出最好的决定。  
  * 主要约束是进入研究阶段的录取基于你在研究冲刺期间的配对，所以如果你在冲刺开始后退出，可能会对你的合作伙伴不利

* #### 会有2026年夏季队列吗？ {#will-there-be-a-summer-2026-cohort?}

  * 我不能确定，但我计划做一个。

* #### 可以远程进行研究阶段吗？ {#is-it-possible-to-do-the-research-phase-remotely?}

  * 可以，这不推荐（很多价值来自在伯克利，有线下队列，互相学习，网络等，如果你远程，与你的合作伙伴工作会更困难），但如果你强烈偏好远程，这完全可以，不会影响你进入研究阶段的机会。  
  * 可能有在伦敦进行研究阶段的选项

* #### 训练和研究阶段之间有很长的间隔，我能在间隔期间做研究吗？ {#there's-a-long-gap-between-the-training-and-research-phase,-can-i-do-research-in-the-gap?}

  * 如果被研究阶段接受，你绝对没有义务在间隔期间做研究。但如果你在探索阶段后真的很兴奋，没有其他义务，并想在间隔期间开始研究阶段项目，我很兴奋一起工作！  
  * MATS项目将不会正式启动，所以你将远程。我期望能够为你提供生活费用和计算的资助。

* #### 如果我有全职工作，我能做探索阶段吗？ {#can-i-do-the-exploration-phase-if-i-have-a-full-time-job?}

  * 这对我来说完全可以，参与者以前也这样做过，但对你来说会更困难  
    1. 你需要全职进行研究冲刺，但有些人为此请假  
    2. 前三周的准备阶段是"工作任意小时"，所以欢迎你只在晚上和周末做你能做的。  
  * 显然，这是一个相当紧张的日程，会让你处于劣势，并且不会与所有雇主合作。抱歉！  
  * 研究阶段是全职的，不能兼职/在一边做。以前有全职工作的参与者要么请了延长的无薪假，要么辞职。

* #### 谁拥有知识产权？ {#who-owns-the-intellectual-property?}

  * 学者拥有他们工作的知识产权，不是我或MATS。  
  * 强烈鼓励学者发表并开源他们的工作，在许可许可下

[^1]: 在我最近的5个队列中，我有3名独立研究人员、9名ML博士生/最近博士毕业生、10名本科生、3名ML硕士生、5名前软件工程师、1名物理博士生、1名ML博士后、1名神经科学博士后、4名量化交易员、1名ML工程师和2名前企业家

[^2]: 注意，最近队列中几乎所有学者都至少发表了一篇共同第一作者会议论文，30篇论文中的许多还太新，无法完成同行评审 - [列表此处](#what-work-have-past-scholars-done?)。但我的首要任务是帮助你做优秀的研究，发表是奖励。

[^3]: 它以解释其中内容的目录开始。

[^4]: 如果你不是第一作者但做出了有意义的研究贡献，请在申请中概述它们是什么

[^5]: 对于看到这个并想到[METR研究](https://metr.org/blog/2025-07-10-early-2025-ai-experienced-os-dev-study/)显示LLM减慢人们速度的任何人，我不认为这转移，尽管不应该做什么的教训仍然存在！那些是在他们熟悉的代码库中工作的有经验的软件工程师，即专家，不是新手

[^6]: 不幸的是，我们实际上无法为申请人提供计算资助。探索和研究阶段有计算预算。

[^7]: 我不完全同意这里的一切，但它是许多研究人员观点的体面概述/聚合

[^8]: 注意，一些论文需要在项目上延长1-2个月才能正确完成，其中一些论文是在延期作为第二个项目完成的

